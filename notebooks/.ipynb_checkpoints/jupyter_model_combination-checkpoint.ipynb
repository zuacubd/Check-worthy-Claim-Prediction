{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/sig/mullah/ir/projects/checkthat/CheckThat-RNCC\n",
      "['random_forest', True]\n",
      "task1-en-file1.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file2.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file3.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file4.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file5.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file6.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file7.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "['svc_rbf', True]\n",
      "task1-en-file1.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file2.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file3.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file4.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file5.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file6.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file7.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "['sgd_log', True]\n",
      "task1-en-file1.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file2.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file3.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file4.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file5.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file6.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file7.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "['nn_lbfgs', True]\n",
      "task1-en-file1.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file2.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file3.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file4.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file5.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file6.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file7.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "['svc_linear', True]\n",
      "task1-en-file1.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file2.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file3.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file4.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file5.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file6.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n",
      "task1-en-file7.txt\n",
      "N\n",
      "W\n",
      "natural\n",
      "W\n"
     ]
    }
   ],
   "source": [
    "#import\n",
    "import os\n",
    "import pickle\n",
    "import io\n",
    "\n",
    "import decimal\n",
    "import collections\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print (cwd)\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "#max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "\n",
    "\n",
    "def float_to_str(f):\n",
    "    \"\"\"\n",
    "    Convert the given float to a string,\n",
    "    without resorting to scientific notation\n",
    "    \"\"\"\n",
    "    d1 = ctx.create_decimal(repr(f))\n",
    "    return format(d1, 'f')\n",
    "\n",
    "def parse_labeled_file(filename):\n",
    "    f = open(filename, encoding=\"utf8\")\n",
    "    array = []\n",
    "\n",
    "    for line in f:\n",
    "        parts = line.split('\\t')\n",
    "        parts[0] = int(parts[0])\n",
    "        parts[len(parts) - 1] = parts[len(parts) - 1].replace('\\n', '')\n",
    "        parts[len(parts) - 1] = int(parts[len(parts) - 1])\n",
    "        array.append(parts)\n",
    "\n",
    "    return array\n",
    "\n",
    "def load_pickle(filepath):\n",
    "    documents_f = open(filepath, 'rb')\n",
    "    file = pickle.load(documents_f)\n",
    "    documents_f.close()\n",
    "\n",
    "    return file\n",
    "\n",
    "def loadTrainSet(path_features, path_labels):\n",
    "    X = load_pickle(path_features)\n",
    "    y = load_pickle(path_labels)\n",
    "    return X, y\n",
    "\n",
    "def loadTestSet(path_features):\n",
    "    X = load_pickle(path_features)\n",
    "    return X\n",
    "\n",
    "def load_output(filename):\n",
    "    with open(filename, 'r') as fread:\n",
    "        lines = fread.readlines()\n",
    "    return lines\n",
    "\n",
    "# Max number of digits for the computed scores\n",
    "ctx = decimal.Context()\n",
    "ctx.prec = 20\n",
    "\n",
    "#features_acro = [\"N\", \"L\", \"C\", \"E\", \"NL\", \"NC\", \"NE\", \"LC\"]\n",
    "#features_acro = [\"N\", \"L\", \"C\", \"W\"]\n",
    "features_acro = [\"NLCW_Q3\", \"NLCW_Q4\"]\n",
    "#features_acro = [\"N\", \"W\"]\n",
    "\n",
    "All_models = [['random_forest', True], ['svc_rbf', True], ['sgd_log', True], ['nn_lbfgs', True], ['svc_linear', True]]\n",
    "#All_models = [['random_forest', True, True, True, True, True], ['svc_rbf', True, True, True, True, False], \n",
    "#              ['sgd_log', True, True, True, True, False], ['nn_lbfgs', True, True, True, True, False], \n",
    "#              ['svc_linear', True, True, True, True, False]]\n",
    "#natural, oversampled, undersampled, combined_ou, balanced\n",
    "\n",
    "test_files_2018 = [\"task1-en-file1.txt\",\"task1-en-file2.txt\",\"task1-en-file3.txt\",\"task1-en-file4.txt\",\n",
    "                  \"task1-en-file5.txt\",\"task1-en-file6.txt\",\"task1-en-file7.txt\"]    \n",
    "\n",
    "for model in All_models:\n",
    "    print (model) \n",
    "    method = model[0]\n",
    "    dist_list = ['natural','oversampled','undersampled','combined_ou','balanced']\n",
    "    \n",
    "    for filename in test_files_2018:\n",
    "        print (filename)\n",
    "        for idx in range(len(features_acro)):\n",
    "            feature_acro_A = features_acro[idx]            \n",
    "            print (feature_acro_A)\n",
    "            for jdx in range(idx+1, len(features_acro)):\n",
    "                feature_acro_B = features_acro[jdx]\n",
    "                print (feature_acro_B)\n",
    "                for d in range(1, len(model)):                    \n",
    "                    if model[d]:\n",
    "                        dist_name = dist_list[d-1]\n",
    "                        print (dist_name)\n",
    "                        scores = []\n",
    "                        output_filename_A = cwd + '/output/' + str(feature_acro_A) + '/' + filename[:-4] + '_' + model[0] + '_' + dist_name + '.txt'\n",
    "                        output_filename_B = cwd + '/output/' + str(feature_acro_B) + '/' + filename[:-4] + '_' + model[0] + '_' + dist_name + '.txt'\n",
    "                \n",
    "                        prediction = load_output(output_filename_A)\n",
    "                        scores.append([])\n",
    "                        for line in prediction:\n",
    "                            cline = line.rstrip().split('\\t')\n",
    "                            scores[0].append(float(cline[1]))\n",
    "                \n",
    "                        prediction = load_output(output_filename_B)\n",
    "                        scores.append([])\n",
    "                        for line in prediction:\n",
    "                            cline = line.rstrip().split('\\t')\n",
    "                            scores[1].append(float(cline[1]))\n",
    "        \n",
    "                        output_file = open(cwd + \"/output/combined_model_feature/\" + filename[:-4] + '_' + model[0] + '_' + feature_acro_A + '_' +  feature_acro_B + '_' + dist_name + '.txt', 'w')\n",
    "                        \n",
    "                        #print (scores_sm)\n",
    "                        scores_sm = np.transpose(scores)\n",
    "                        #print (len(scores_sm))\n",
    "                        #print (scores_sm)\n",
    "                        scores_minmax = min_max_scaler.fit_transform(scores_sm)\n",
    "                        #print (scores_minmax[0])\n",
    "                        for i in range(len(scores_sm)):\n",
    "                            vote = (scores_minmax[i]>=.5).sum()\n",
    "                            if vote >= 1:\n",
    "                                #score = np.max(scores_minmax[i])\n",
    "                                score = np.sum(scores_minmax[i]) * vote\n",
    "                            else:\n",
    "                                score = np.mean(scores_minmax[i])\n",
    "                            #score = np.sum(scores_minmax[i])\n",
    "                            #score = np.prod(scores_minmax[i])\n",
    "                            #vote = (scores_sm[i]>=.5).sum()\n",
    "                            #if vote >= 1:\n",
    "                            #    score = np.max(scores_sm[i])\n",
    "                            #else:\n",
    "                            #    score = np.mean(scores_sm[i])\n",
    "                            #if vote >= 1:\n",
    "                            #    score = np.max(scores_sm[i])\n",
    "                            #else:\n",
    "                            #    score = np.min(scores_sm[i])\n",
    "                            output_file.write(str(i + 1) + \"\\t\" + float_to_str(score) + \"\\n\")\n",
    "                        output_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.        , 1.        ],\n",
       "       [1.        , 0.5       , 0.33333333],\n",
       "       [0.        , 1.        , 0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
